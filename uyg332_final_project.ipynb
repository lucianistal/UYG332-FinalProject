{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718ca896",
   "metadata": {},
   "source": [
    "# UYG332 - Image Processing Final Project\n",
    "\n",
    "**Name**: LucÃ­a Nistal Palacios  \n",
    "**Student ID**: [Tu ID aquÃ­]  \n",
    "\n",
    "This notebook presents the solutions to six image processing problems using Python and OpenCV.  \n",
    "Each problem uses a specific image and demonstrates the application of various image processing techniques discussed in the course.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbc5eb2",
   "metadata": {},
   "source": [
    "## ðŸ“š Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51d37b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Helper function to display images\n",
    "def show_image(img, title='', cmap_type='gray'):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    if len(img.shape) == 3:\n",
    "        cmap_type = None\n",
    "    plt.imshow(img, cmap=cmap_type)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8253b82d",
   "metadata": {},
   "source": [
    "## ðŸ§© Problem 1 â€“ `tf2_engineer.jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3ec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read and display the original image\n",
    "img1 = cv2.imread('tf2_engineer.jpg')\n",
    "img1_rgb = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "show_image(img1_rgb, 'Original Image', cmap_type=None)\n",
    "\n",
    "# Step 2: Find the center and intensity\n",
    "h, w, _ = img1.shape\n",
    "yc, xc = h // 2, w // 2\n",
    "center_intensity = img1[yc, xc]\n",
    "print(f\"Center coordinates: ({yc}, {xc})\")\n",
    "print(f\"Center pixel intensity (BGR): {center_intensity}\")\n",
    "\n",
    "# Step 3: Draw rectangle\n",
    "patch_color = (0xa8, 0x9e, 0x32)  # BGR\n",
    "top_left = (xc - 20, yc - 15)\n",
    "bottom_right = (xc + 20, yc + 15)\n",
    "cv2.rectangle(img1, top_left, bottom_right, patch_color, -1)\n",
    "\n",
    "# Step 4: New intensity at center\n",
    "patch_center_intensity = img1[yc, xc]\n",
    "print(f\"New intensity at center after patch: {patch_center_intensity}\")\n",
    "\n",
    "# Step 5: Display updated image\n",
    "img1_rgb_updated = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "show_image(img1_rgb_updated, 'Image with Color Patch', cmap_type=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a62c494",
   "metadata": {},
   "source": [
    "## ðŸ§© Problem 2 â€“ `einstein.tiff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c2088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read grayscale\n",
    "img2 = cv2.imread('einstein.tiff', cv2.IMREAD_GRAYSCALE)\n",
    "show_image(img2, 'Original Grayscale')\n",
    "\n",
    "# Step 2: Negative\n",
    "img2_neg = 255 - img2\n",
    "show_image(img2_neg, 'Negative Image')\n",
    "\n",
    "# Step 4: Pixel value comparison\n",
    "h, w = img2.shape\n",
    "for _ in range(5):\n",
    "    y, x = random.randint(0, h-1), random.randint(0, w-1)\n",
    "    orig = img2[y, x]\n",
    "    neg = img2_neg[y, x]\n",
    "    print(f\"Pixel ({y},{x}) - Original: {orig}, Negative: {neg}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee717bc",
   "metadata": {},
   "source": [
    "## ðŸ§© Problem 3 â€“ `pout.tiff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a40c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read grayscale\n",
    "img3 = cv2.imread('pout.tiff', cv2.IMREAD_GRAYSCALE)\n",
    "show_image(img3, 'Original Image')\n",
    "\n",
    "# Step 2: Log transform\n",
    "c = 255 / np.log(1 + np.max(img3))\n",
    "log_img = c * np.log(1 + img3.astype(np.float32))\n",
    "log_img = np.uint8(np.clip(log_img, 0, 255))\n",
    "show_image(log_img, 'Log Transformed')\n",
    "\n",
    "# Step 3: Inverse log transform of original\n",
    "inv_log_orig = np.exp(img3 / c) - 1\n",
    "inv_log_orig = np.uint8(np.clip(inv_log_orig, 0, 255))\n",
    "show_image(inv_log_orig, 'Inverse Log of Original')\n",
    "\n",
    "# Step 4: Inverse log of log image\n",
    "inv_log_back = np.exp(log_img / c) - 1\n",
    "inv_log_back = np.uint8(np.clip(inv_log_back, 0, 255))\n",
    "show_image(inv_log_back, 'Inverse Log of Log Image')\n",
    "\n",
    "# Step 5: Comments\n",
    "print(\"Comment: The inverse log of the log image approximates the original image, but minor differences may occur due to rounding.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24d3d7",
   "metadata": {},
   "source": [
    "## ðŸ§© Problem 4 â€“ `moon.tiff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1957d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "img4 = cv2.imread('moon.tiff', cv2.IMREAD_GRAYSCALE)\n",
    "show_image(img4, 'Original Moon Image')\n",
    "\n",
    "def unsharp_mask_spatial(img, k):\n",
    "    blur = cv2.GaussianBlur(img, (9,9), 0)\n",
    "    mask = cv2.subtract(img, blur)\n",
    "    sharp = cv2.addWeighted(img, 1, mask, k, 0)\n",
    "    return sharp\n",
    "\n",
    "for k in [0.2, 0.5, 1.0]:\n",
    "    result = unsharp_mask_spatial(img4, k)\n",
    "    show_image(result, f\"Spatial Unsharp Masking (k={k})\")\n",
    "\n",
    "def high_pass_filter(shape, D0):\n",
    "    rows, cols = shape\n",
    "    crow, ccol = rows//2 , cols//2\n",
    "    H = np.zeros((rows, cols), np.float32)\n",
    "    for u in range(rows):\n",
    "        for v in range(cols):\n",
    "            D = np.sqrt((u - crow)**2 + (v - ccol)**2)\n",
    "            if D > D0:\n",
    "                H[u,v] = 1\n",
    "    return H\n",
    "\n",
    "def unsharp_mask_freq(img, k, D0):\n",
    "    dft = np.fft.fft2(img)\n",
    "    dft_shift = np.fft.fftshift(dft)\n",
    "    H = high_pass_filter(img.shape, D0)\n",
    "    result_shift = (1 + k * H) * dft_shift\n",
    "    img_back = np.fft.ifft2(np.fft.ifftshift(result_shift))\n",
    "    img_back = np.abs(img_back)\n",
    "    img_back = np.uint8(np.clip(img_back, 0, 255))\n",
    "    return img_back\n",
    "\n",
    "for k in [0.2, 0.5, 1.0]:\n",
    "    result = unsharp_mask_freq(img4, k, 30)\n",
    "    show_image(result, f\"Frequency Unsharp Masking (k={k})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2cb5bc",
   "metadata": {},
   "source": [
    "## ðŸ§© Problem 5 â€“ `pcb.tiff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcfcd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img5 = cv2.imread('pcb.tiff', cv2.IMREAD_GRAYSCALE)\n",
    "show_image(img5, 'Original PCB Image')\n",
    "\n",
    "# Histogram\n",
    "plt.hist(img5.ravel(), 256, [0,256])\n",
    "plt.title('Histogram')\n",
    "plt.show()\n",
    "\n",
    "# Assumed salt-and-pepper noise\n",
    "median = cv2.medianBlur(img5, 3)\n",
    "show_image(median, 'After Median Filtering')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178f2f42",
   "metadata": {},
   "source": [
    "## ðŸ§© Problem 6 â€“ `pollen.tiff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ed8811",
   "metadata": {},
   "outputs": [],
   "source": [
    "img6 = cv2.imread('pollen.tiff', cv2.IMREAD_GRAYSCALE)\n",
    "show_image(img6, 'Original Pollen Image')\n",
    "\n",
    "# Histogram\n",
    "plt.hist(img6.ravel(), 256, [0,256])\n",
    "plt.title('Histogram of Original Image')\n",
    "plt.show()\n",
    "\n",
    "print(\"Comment: Image seems to have low contrast and possibly blur.\")\n",
    "\n",
    "# First approach: Histogram Equalization\n",
    "equalized = cv2.equalizeHist(img6)\n",
    "show_image(equalized, 'Histogram Equalization')\n",
    "\n",
    "# Second approach: CLAHE\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "clahe_img = clahe.apply(img6)\n",
    "show_image(clahe_img, 'CLAHE Enhancement')\n",
    "\n",
    "print(\"Both methods improve contrast. CLAHE is better at avoiding over-enhancement in uniform areas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5979caf",
   "metadata": {},
   "source": [
    "## âœ… Conclusion\n",
    "\n",
    "This project applied a variety of image processing techniques including image transformation, enhancement in both spatial and frequency domains, noise reduction, and contrast improvement.  \n",
    "Each task reinforced the use of OpenCV's powerful tools and improved my understanding of digital image processing.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
